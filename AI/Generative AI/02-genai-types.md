# Types of Generative AI Models

## Four Types
1. Generative Adversarial Networks (GANs): These models are game-changers in image generation, creating everything from art to realistic photos.

2. Variational Autoencoders (VAEs): VAEs are great for tasks that involve compressing and generating high-quality images, offering applications in style transfer and more.

3. Transformer Models: Known for their prowess in text, transformer models like GPT are revolutionizing text generation, translation, and automated writing.

4. Restricted Boltzmann Machines (RBMs): RBMs excel in understanding complex data patterns, aiding in tasks like feature learning and topic modeling.

## Language and Image Models
Generative language models learn about patterns in language through training data. Then, given some text, they predict what comes next.

Generative image models produce new images using techniques like diffusion. Then, given a prompt or related imagery, they transform random noise into images or generate images from prompts.

## Research Paper
The esearch paper that changed everything, called 'Attention is All You Need' [here](https://lnkd.in/gaJCDKQH).

1. 𝗧𝗿𝗮𝗻𝘀𝗳𝗼𝗿𝗺𝗲𝗿𝘀: The paper presented the transformer model, moving away from traditional Deep Learning methodologies that were quite limiting such as Recurrent Neural Network (RNNs) and Convolutional Neural Network (CNNs) in NLP.
​
2. 𝗦𝗲𝗹𝗳-𝗔𝘁𝘁𝗲𝗻𝘁𝗶𝗼𝗻 𝗠𝗲𝗰𝗵𝗮𝗻𝗶𝘀𝗺: Transformers use self-attention to efficiently process different parts of input data.
​
3. 𝗜𝗺𝗽𝗿𝗼𝘃𝗲𝗱 𝗣𝗮𝗿𝗮𝗹𝗹𝗲𝗹𝗶𝘇𝗮𝘁𝗶𝗼𝗻: Transformers enable more efficient training through better parallelization compared to RNNs.
​
4. 𝗘𝗻𝗵𝗮𝗻𝗰𝗲𝗱 𝗡𝗟𝗣 𝗣𝗲𝗿𝗳𝗼𝗿𝗺𝗮𝗻𝗰𝗲: They significantly outperform previous models in tasks like machine translation and text summarization.
​
5. 𝗕𝗮𝘀𝗶𝘀 𝗳𝗼𝗿 𝗔𝗱𝘃𝗮𝗻𝗰𝗲𝗱 𝗠𝗼𝗱𝗲𝗹𝘀: The transformer architecture underpins major NLP models like BERT and GPT, enhancing language processing capabilities.
​
[Next](./03-trad-ml.md)
